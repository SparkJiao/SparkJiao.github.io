---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About Me

My name is Fangkai Jiao (焦方锴). I am a third-year PhD candidate at Nanyang Technological University and Institute of Infocomm Research (I<sup>2</sup>R), A*STAR, with [A*STAR SINGA Scholarship](https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa). I am fortunate to be supervised by [Prof. Shafiq Joty](https://raihanjoty.github.io/), [Prof. Nancy F. Chen](https://sites.google.com/site/nancyfchen/home) and [Prof. Aixin Sun](https://personal.ntu.edu.sg/axsun/). Before that, I obtained both my M.Eng. and B.Eng. degree from Shandong University in 2022 and 2019, respecitively, under the supervision of [Prof. Liqiang Nie](https://liqiangnie.github.io/). I also work closely with [Dr. Yangyang Guo](https://guoyang9.github.io/), [Dr. Zhiyang Teng](https://zeeeyang.github.io/) and [Zhengyuan Liu](https://scholar.google.com.sg/citations?user=tqzidGsAAAAJ&hl=en). I have interned at CoAI Lab, Tsinghua University, mentored by [Prof. Minlie Huang](https://coai.cs.tsinghua.edu.cn/hml), DAMO Academy, Alibaba-inc, mentored by [Dr. Feng Ji](https://scholar.google.com/citations?user=BxWZ-ZgAAAAJ&hl=zh-CN) and [Dr. Feng-Lin Li](https://scholar.google.it/citations?user=xo_dfnMAAAAJ&hl=en), and Langboat Technology. 

My primary research interest includes self/weak-supervised training and machine reasoning with large language models. I'm also one of the main contributors to [PandaLLM](https://github.com/dandelionsllm/pandallm) project.



## News

07/26/2024: UNK-VQA is accepted by TPAMI.

05/15/2024: Joined MSRA as an intern.

04/01/2024: Our survey and the integrated LLM contamination detection tool is released. Check the [paper](https://arxiv.org/abs/2404.00699) and [Github repository](https://github.com/ntunlp/LLMSanitize).

03/14/2024: Two papers are accepted by NAACL 2024.

10/08/2023: Our survey is accepted by Findings of EMNLP 2023.

08/10/2023: Weights of Panda-Llama2-13B & Panda-Llama2-13B-Chat are released. And PandaLLM project is also upgraded to PandaLLMOps. Check our tutorial about large scale distributed training [here](https://panda-tutorial.readthedocs.io/en/latest/quick_start.html).

06/24/2023: PandaLLM-13B-Chat weights are released. Check it [here](https://huggingface.co/chitanda/llama-panda-13b-zh-wudao-chat-delta).

06/13/2023: PandaLLM-13B-Chat on telegram bot is released. Check it at our [repo](https://github.com/dandelionsllm/pandallm#%E6%9C%80%E8%BF%91%E6%9B%B4%E6%96%B0).

05/14/2023: PandaLLM-13B is released.

05/02/2023: Our Chinese LLM - Panda LLM is released with 7B weights. Better reasoning capability. Check it [here](https://github.com/dandelionsllm/pandallm)!

03/15/2023: Our survey about mutli-modal retrieval augmented generation is uploaded to [arxiv](https://arxiv.org/abs/2303.10868).

10/05/2022: One paper is accepted by IEEE/ACM Transactions of Audio, Speech and Language Processing (TASL).

03/31/2022: One paper is accepted by SIGIR 2022.

02/24/2022: One paper is accepted by Findings of ACL 2022.

02/09/2022: Our system, MERIt (Deberta-v2-xxlarge) achieves a new SOTA on [Reclor](https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347) leaderboard.

11/05/2021: Our system for logical reasoning achieves the Top-1 results among single models on [Reclor](https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347) leaderboard.

## Academic Services

### Reviewer

**Confernece**: ACL Rolling Review, EMNLP 2023, ACM MM 2022 (workshop), ICLR 2024

**Journal**: IEEE/ACM TASL, IEEE TKDE, IEEE TMM
